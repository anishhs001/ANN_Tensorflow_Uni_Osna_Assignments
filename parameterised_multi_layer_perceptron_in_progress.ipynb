{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8db45146",
   "metadata": {},
   "source": [
    "## 2.1 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "id": "1ea693dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "id": "51ec500b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "print(digits.data.shape)\n",
    "plt.gray()\n",
    "plt.matshow(digits.images[1796])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "id": "1a3b5630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "       [ 0.,  0., 10., ..., 12.,  1.,  0.]])"
      ]
     },
     "execution_count": 967,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "id": "97289086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_target = []\n",
    "# for i in range(0,1797):\n",
    "#     input_target.append((digits.images[i],digits.target[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "id": "546f5c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.array(digits.images)\n",
    "targets = np.array(digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "id": "ff0c1ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.gray()\n",
    "plt.matshow(inputs[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "id": "e71b224b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_inputs = inputs.reshape(1797,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 972,
   "id": "d33c01b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_inputs_f32 = reshaped_inputs.astype('float32')/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "id": "d4ecf9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 973,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_array = np.zeros((1797,10))\n",
    "for i in range(1797):\n",
    "    target_array[i][targets[i]]=1\n",
    "target_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "id": "dc453c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 974,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "id": "8bffccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_target = []\n",
    "for i in range(len(reshaped_inputs_f32)):\n",
    "    input_target.append((reshaped_inputs_f32[i],target_array[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "id": "acceptable-deputy",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batch_size = 1500\n",
    "number_of_layers_in_mlp = 3\n",
    "activation_functions_list = ['sigmoid','sigmoid','softmax']\n",
    "each_layer_perceptron_list = [mini_batch_size,500,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "id": "9f22345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_minibatch(input_target=input_target):\n",
    "    random.shuffle(input_target)\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for i in range(len(input_target)):\n",
    "        inputs.append(input_target[i][0])\n",
    "        targets.append(input_target[i][1])\n",
    "    inputs_cp = inputs.copy()\n",
    "    targets_cp = targets.copy()\n",
    "    minibatch_input = np.array(inputs_cp[:mini_batch_size])\n",
    "    minibatch_target = np.array(targets_cp[:mini_batch_size])\n",
    "    \n",
    "    del inputs_cp[0:mini_batch_size]\n",
    "    del targets_cp[0:mini_batch_size]\n",
    "    \n",
    "    yield (minibatch_input,minibatch_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "id": "306ebd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_input, mini_target = next(generate_minibatch())\n",
    "\n",
    "initial_input_size = mini_input.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2208b4e",
   "metadata": {},
   "source": [
    "## 2.2 & 2.3 Sigmoid Function and Softmax Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "id": "23b2f1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class activation_functions:\n",
    "\n",
    "    def sigmoid(X):\n",
    "        return 1 / (1+np.exp(-X))\n",
    "\n",
    "    def softmax(Z):\n",
    "        return np.exp(Z) / np.sum(np.exp(Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-spring",
   "metadata": {},
   "source": [
    "## 2.4 MLP weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "id": "honest-disorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_weights = []\n",
    "forward_biases = []\n",
    "forward_activated_values = []\n",
    "forward_preactivated_values = []\n",
    "\n",
    "class mlp_forward_layer:\n",
    "    def __init__(self, activation_function, layer_size, input_size):\n",
    "        self.activation_function = activation_function\n",
    "        self.layer_size = layer_size\n",
    "        self.input_size = input_size\n",
    "        \n",
    "    def attributes(self):\n",
    "        W=np.random.normal(0,0.2,size=(self.layer_size, self.input_size))\n",
    "        forward_weights.append(W)\n",
    "        b=np.zeros(shape=(self.layer_size,1))\n",
    "        forward_biases.append(b)\n",
    "        return W,b\n",
    "\n",
    "    def forward_function(self, X, W, b, i):\n",
    "        if W == -1 or b == -1:\n",
    "            W,b = self.attributes()\n",
    "        else:\n",
    "            W = W[i]\n",
    "            b = b[i]\n",
    "        \n",
    "        Z = W.dot(X) + b\n",
    "        \n",
    "        forward_preactivated_values.append(X)\n",
    "        if((self.activation_function == 'sigmoid') or (self.activation_function == 'Sigmoid')):\n",
    "            activation_values = activation_functions.sigmoid(Z)\n",
    "        elif((self.activation_function == 'softmax') or (self.activation_function == 'Softmax')):\n",
    "            activation_values = activation_functions.softmax(Z)\n",
    "        forward_activated_values.append(activation_values)\n",
    "        return np.array(activation_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-horror",
   "metadata": {},
   "source": [
    "## 2.5 Putting together the MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "id": "pressing-denver",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_list = []\n",
    "input_size_list = []\n",
    "\n",
    "class mlp_forward:\n",
    "\n",
    "    def __init__(self, no_of_layers, size_of_layer, layer_activation_function_string_list):\n",
    "        self.no_of_layers = no_of_layers\n",
    "        self.size_of_layer = size_of_layer\n",
    "        self.layer_activation_function_string_list = layer_activation_function_string_list\n",
    "        \n",
    "    def mlp_forward_final_calculation(self, X, W = -1, b = -1, initial_input_size = initial_input_size):\n",
    "        outputs_list.append(X)\n",
    "        input_size_list.append(initial_input_size)\n",
    "        for i in range(self.no_of_layers):\n",
    "            size_value = int(input_size_list[-1])\n",
    "            mlp_layer_i_output = mlp_forward_layer(self.layer_activation_function_string_list[i], self.size_of_layer[i], size_value).forward_function(np.array(outputs_list[-1]),W,b,i)\n",
    "            outputs_list.append(mlp_layer_i_output)\n",
    "            input_size_list.append(mlp_layer_i_output.shape[0])\n",
    "        return outputs_list[-1].T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "departmental-easter",
   "metadata": {},
   "source": [
    "## 2.6 CCE Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "id": "least-hygiene",
   "metadata": {},
   "outputs": [],
   "source": [
    "class loss_function:\n",
    "\n",
    "    def cce_loss(actual_output,predicted_output):\n",
    "        return ((-1/mini_batch_size)*np.sum(actual_output*(np.log(predicted_output))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "id": "prepared-patio",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.549728799839125"
      ]
     },
     "execution_count": 983,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_output = mlp_forward(number_of_layers_in_mlp,each_layer_perceptron_list,activation_functions_list).mlp_forward_final_calculation(mini_input.T)\n",
    "loss_function.cce_loss(mini_target,predicted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "id": "endless-comedy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 10)"
      ]
     },
     "execution_count": 984,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "id": "decent-preview",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 1500)"
      ]
     },
     "execution_count": 985,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_activated_values[-2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-flush",
   "metadata": {},
   "source": [
    "## 3.1, 3.2 & 3.3 CCE, Sigmoid and Weights Backwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "id": "competent-friend",
   "metadata": {},
   "outputs": [],
   "source": [
    "class backward_functions:\n",
    "\n",
    "    def cce_deriv(actual_output,predicted_output):\n",
    "        print(actual_output.shape, predicted_output.shape)\n",
    "        return predicted_output - actual_output\n",
    "\n",
    "    def sigmoid_deriv(Z):\n",
    "        return activation_functions.sigmoid(Z)*(1-activation_functions.sigmoid(Z))\n",
    "    \n",
    "    def weights_backwards(current_layer_deriv_input,previous_layer_activated_data):\n",
    "        print('Weight backwards',current_layer_deriv_input.shape,previous_layer_activated_data.shape)\n",
    "        return (1/mini_batch_size)*(previous_layer_activated_data*(current_layer_deriv_input.T))\n",
    "    \n",
    "    def bias_backwards(current_layer_deriv_input):\n",
    "        print(np.sum(current_layer_deriv_input))\n",
    "        return (1/mini_batch_size)*np.sum(current_layer_deriv_input)\n",
    "\n",
    "    def sigmoid_backwards(current_layer_weights,previous_layer_deriv_input,current_layer_preactivation_data):\n",
    "        print('Sigmoid backwards',current_layer_weights.shape,previous_layer_deriv_input.shape,current_layer_preactivation_data.shape)\n",
    "        return (current_layer_weights.dot(backward_functions.sigmoid_deriv(current_layer_preactivation_data.dot(previous_layer_deriv_input))))\n",
    "\n",
    "    def update_parameters(W,dW,b,db,alpha=0.001):\n",
    "        print(W.shape,dW.shape,b.shape,db.shape)\n",
    "        return (W - (alpha*dW)),(b - (alpha*db))\n",
    "    \n",
    "    def get_predictions(A2):\n",
    "        return np.argmax(A2, 0)\n",
    "\n",
    "    def get_accuracy(predictions, Y):\n",
    "        print(predictions, Y)\n",
    "        return np.sum(predictions == Y) / Y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "id": "portuguese-column",
   "metadata": {},
   "outputs": [],
   "source": [
    "backwards_weights = []\n",
    "backwards_biases = []\n",
    "backwards_deriv_values = []\n",
    "\n",
    "class mlp_backward_layer:\n",
    "\n",
    "    def __init__(self,X,Y,forward_weights=forward_weights,forward_biases=forward_biases,forward_activated_values=forward_activated_values):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.forward_weights = forward_weights\n",
    "        self.forward_biases = forward_biases\n",
    "        self.forward_activated_values = forward_activated_values\n",
    "    \n",
    "    def feed_backward_function(self):\n",
    "        for i in range(number_of_layers_in_mlp):\n",
    "            if i==0 and activation_functions_list[-1].lower()=='softmax':\n",
    "                predicted_output = mlp_forward(number_of_layers_in_mlp,each_layer_perceptron_list,activation_functions_list).mlp_forward_final_calculation(mini_input.T)\n",
    "                backwards_deriv_values.append(backward_functions.cce_deriv(self.Y,predicted_output))\n",
    "                dW = backward_functions.weights_backwards(backwards_deriv_values[-1],forward_activated_values[-(i+1)])\n",
    "                db = backward_functions.bias_backwards(backwards_deriv_values[-1])\n",
    "                print(dW.shape,db.shape)\n",
    "                updated_W, updated_b = backward_functions.update_parameters(forward_weights[(-(i+1))],dW,forward_biases[(-(i+1))],db)\n",
    "                backwards_weights.append(updated_W)\n",
    "                backwards_biases.append(updated_b)\n",
    "                \n",
    "            elif i>0 and activation_functions_list[-(i+1)].lower()=='sigmoid':\n",
    "                backwards_deriv_values.append(backward_functions.sigmoid_backwards(forward_weights[-(i+1)],backwards_deriv_values[-1],forward_preactivated_values[-(i+1)]))\n",
    "                dW = backward_functions.weights_backwards(backwards_deriv_values[-1],forward_activated_values[-(i+1)])\n",
    "                db = backward_functions.bias_backwards(backwards_deriv_values[-1])\n",
    "                updated_W, updated_b = backward_functions.update_parameters(forward_weights[(-(i+1))],dW,forward_biases[(-(i+1))],db)\n",
    "                backwards_weights.append(updated_W)\n",
    "                backwards_biases.append(updated_b)\n",
    "            \n",
    "            else:\n",
    "                print('Please try again')\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "id": "front-things",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, Y, alpha = 0.001, iterations = 100):\n",
    "    for i in range(iterations):\n",
    "        if i==0:\n",
    "            predicted_output = mlp_forward(number_of_layers_in_mlp,each_layer_perceptron_list,activation_functions_list).mlp_forward_final_calculation(mini_input.T)\n",
    "        else:\n",
    "            predicted_output = mlp_forward(number_of_layers_in_mlp,each_layer_perceptron_list,activation_functions_list).mlp_forward_final_calculation(mini_input.T, current_W, current_b)\n",
    "        mlp_backward_layer(mini_input, mini_target).feed_backward_function()\n",
    "        current_W, current_b = backwards_weights[-number_of_layers_in_mlp:][::-1], backwards_biases[-number_of_layers_in_mlp:][::-1]\n",
    "        if i % 10 == 0:\n",
    "            print(\"Iteration: \", i)\n",
    "            predictions = get_predictions(predicted_output)\n",
    "            print(get_accuracy(predicted_output, Y))\n",
    "    return (current_W, current_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "id": "another-cover",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 10) (1500, 10)\n",
      "Weight backwards (1500, 10) (10, 1500)\n",
      "-1499.0\n",
      "(10, 1500) ()\n",
      "(10, 500) (10, 1500) (10, 1) ()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10,500) (10,1500) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-989-35283942e242>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mW1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmini_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.010\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-988-b6e4231cb737>\u001b[0m in \u001b[0;36mgradient_descent\u001b[1;34m(X, Y, alpha, iterations)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mpredicted_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmlp_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber_of_layers_in_mlp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meach_layer_perceptron_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation_functions_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmlp_forward_final_calculation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmini_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mmlp_backward_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmini_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmini_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_backward_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mcurrent_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackwards_weights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnumber_of_layers_in_mlp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackwards_biases\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnumber_of_layers_in_mlp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-987-8ee977ad707b>\u001b[0m in \u001b[0;36mfeed_backward_function\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     20\u001b[0m                 \u001b[0mdb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackward_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_backwards\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackwards_deriv_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                 \u001b[0mupdated_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdated_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackward_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforward_weights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mforward_biases\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m                 \u001b[0mbackwards_weights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdated_W\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[0mbackwards_biases\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdated_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-986-ac16bf94f5ac>\u001b[0m in \u001b[0;36mupdate_parameters\u001b[1;34m(W, dW, b, db, alpha)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10,500) (10,1500) "
     ]
    }
   ],
   "source": [
    "W1, b1 = gradient_descent(mini_input, mini_target, 0.010, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "id": "structured-european",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 990,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(forward_biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-business",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
